":ID","name",":LABEL","understanding_criteria","schema_version","description","author","creation_date","last_updated","total_concepts:int","total_subconcepts:int"
"machine_learning_insights","Machine Learning Insights Curriculum","Curriculum","","1.1.0","A structured learning curriculum for machine learning concepts, designed for educational purposes. It includes core concepts, subconcepts, and fundamental definitions with understanding criteria.","AI Curriculum Design Team","2025-01-28","2025-07-28",10,34
"MLF_001","Machine Learning Fundamentals and Definitions","Concept","Can explain that AI and machine learning are computer systems that copy how human brains learn, using math to represent brain connections and learning processes;Understands that machines learn by practicing with examples and getting better through repeated training cycles, rather than being programmed with specific instructions;Recognizes that deep learning uses many layers of artificial brain cells to handle complex data, requiring large amounts of information to work effectively;Can describe how machine learning abilities emerge naturally from training without explicit programming, and how performance stabilizes over time;Shows understanding of the historical progression from 1940s mechanical calculators to modern powerful computers with graphics processing units",,,,,,,
"MLF_001_SC01","Artificial Intelligence refers to systems modeled on mathematical representations of human neuronal synapses that aim to imitate human learning","SubConcept","Can explain that AI uses mathematical formulas and numbers to copy how brain cells connect and communicate;Understands that computers try to imitate how humans learn by creating simplified models of brain processes;Recognizes that AI systems are not actual brains but mathematical approximations of brain functions;Can describe how chemical signals between brain cells are represented using computer calculations;Shows awareness that AI aims to recreate human learning patterns through computational methods",,,,,,,
"MLF_001_SC01_D01","Mathematical representation: Using numbers, formulas, and calculations to describe how things work in the real world","Definition","Mentions 'numbers', 'formulas', 'calculations', or 'math';References 'describe', 'represent', or 'model';Includes 'real world', 'nature', or 'phenomena';Shows understanding that math is a tool for description;Indicates math captures patterns or relationships",,,,,,,
"MLF_001_SC01_D02","Neuronal synapses: Connection points between brain cells where chemical signals jump from one cell to another to send messages","Definition","Mentions 'brain cells', 'neurons', or 'nerve cells';References 'connection', 'gap', or 'junction';Includes 'chemical signals', 'messages', or 'communication';Shows understanding of signal transmission between cells;Indicates synapses enable brain communication",,,,,,,
"MLF_001_SC01_D03","System modeling: Creating simplified versions of complex processes using math or computer programs to study how they work","Definition","Mentions 'simplified', 'model', or 'representation';References 'complex processes' or 'systems';Includes 'study', 'understand', or 'analyze';Shows understanding that models are not exact copies;Indicates purpose is to learn how things work",,,,,,,
"MLF_001_SC01_D04","Human learning patterns: How our brains naturally learn through making connections, remembering experiences, and changing behavior based on results","Definition","Mentions 'brain', 'learning', or 'memory';References 'connections', 'experience', or 'practice';Includes 'behavior change' or 'adaptation';Shows understanding that learning involves neural changes;Indicates learning is based on experience and feedback",,,,,,,
"MLF_001_SC01_D05","Computational imitation: Using computer programs and mathematical steps to copy how biological processes or thinking works","Definition","Mentions 'computer', 'programs', or 'algorithms';References 'copy', 'imitate', or 'mimic';Includes 'biological', 'brain', or 'thinking';Shows understanding of copying natural processes;Indicates computers can simulate biological functions",,,,,,,
"MLF_001_SC02","Machine Learning is a branch of AI where machines learn and make decisions from data through iterative cycles of training","SubConcept","Can explain that ML involves computers getting better at tasks by practicing with examples;Understands that machines follow step-by-step instructions to find patterns in information;Recognizes that training involves showing computers many examples with correct answers;Can describe how machines improve through repeated practice and learning from mistakes;Shows understanding that ML systems make decisions based on rules learned from data",,,,,,,
"MLF_001_SC02_D01","Algorithm: A set of step-by-step instructions that tells a computer how to transform input information into useful output","Definition","Mentions 'steps', 'instructions', or 'procedure';References 'computer' or 'machine';Includes 'input' and 'output';Shows understanding of sequential process;Indicates transformation of information",,,,,,,
"MLF_001_SC02_D02","Training data: Collections of examples that show both questions and correct answers, used to teach computers to recognize patterns","Definition","Mentions 'examples', 'data', or 'information';References 'questions and answers' or 'input-output pairs';Includes 'teach', 'learn', or 'training';Shows understanding of learning from examples;Indicates purpose is pattern recognition",,,,,,,
"MLF_001_SC02_D03","Iterative process: Repeating the same learning steps over and over, where each round improves performance based on mistakes from previous rounds","Definition","Mentions 'repeat', 'cycle', or 'iteration';References 'improve' or 'get better';Includes 'mistakes', 'errors', or 'feedback';Shows understanding of gradual improvement;Indicates learning from previous attempts",,,,,,,
"MLF_001_SC02_D04","Pattern recognition: The ability to spot similarities, trends, and repeating structures in data that help make predictions about new examples","Definition","Mentions 'patterns', 'similarities', or 'trends';References 'spot', 'find', or 'identify';Includes 'data' or 'information';Shows understanding of finding regularities;Indicates patterns help make predictions",,,,,,,
"MLF_001_SC02_D05","Decision-making framework: A logical system that takes in information and uses learned rules to choose what action to take","Definition","Mentions 'decision', 'choice', or 'action';References 'rules', 'logic', or 'system';Includes 'information' or 'input';Shows understanding of systematic choice process;Indicates rules guide decisions",,,,,,,
"MLF_001_SC03","Deep Learning is a subset of ML that uses neural networks to enhance learning capacity from large datasets","SubConcept","Can explain that deep learning uses computer systems inspired by how brain cells connect;Understands that neural networks have many layers of simple processing units working together;Recognizes that deep learning needs large amounts of data to work effectively;Can describe how these systems automatically find important characteristics in data;Shows understanding that learning happens in stages from simple to complex concepts",,,,,,,
"MLF_001_SC03_D01","Neural network: A computer system inspired by how brain cells connect, made of many simple processing units linked together","Definition","Mentions 'brain', 'neurons', 'brain cells';References 'network', 'connections', or 'linked';Includes 'simple units' or 'processing units';Shows understanding of brain inspiration;Indicates many units working together",,,,,,,
"MLF_001_SC03_D02","Layers and nodes: Organization where individual processing units (like artificial brain cells) are arranged in stacked levels that pass information forward","Definition","Mentions 'layers', 'levels', or 'stacked';References 'nodes', 'units', or 'neurons';Includes 'information flow' or 'pass forward';Shows understanding of hierarchical organization;Indicates structured arrangement of processing units",,,,,,,
"MLF_001_SC03_D03","Large datasets: Collections containing thousands to millions of examples needed to teach complex computer models without memorizing specific cases","Definition","Mentions 'large', 'thousands', 'millions', or 'big';References 'examples', 'data', or 'cases';Includes 'teach', 'train', or 'learn';Shows understanding of scale requirements;Indicates purpose is learning, not memorizing",,,,,,,
"MLF_001_SC03_D04","Feature extraction: The automatic process of finding and highlighting the most important characteristics or patterns hidden in raw data","Definition","Mentions 'features', 'characteristics', or 'properties';References 'find', 'extract', or 'identify';Includes 'important', 'relevant', or 'key';Shows understanding of automatic discovery;Indicates finding hidden information in data",,,,,,,
"MLF_001_SC03_D05","Hierarchical learning: Learning in stages where simple concepts are combined step-by-step to understand increasingly complex ideas","Definition","Mentions 'stages', 'levels', or 'hierarchy';References 'simple to complex' or 'step-by-step';Includes 'combine' or 'build upon';Shows understanding of progressive learning;Indicates building complexity gradually",,,,,,,
"MLF_001_SC04","ML algorithms emerge from training on datasets iteratively without need for specific programming","SubConcept","Can explain that complex computer abilities appear naturally when simple rules are repeated many times;Understands that computers improve by practicing with examples and adjusting their internal settings;Recognizes that the system automatically fine-tunes itself to reduce errors and improve accuracy;Can describe how computers discover patterns directly from examples rather than being programmed with specific instructions;Shows understanding that repeated practice leads to stable performance that eventually stops improving significantly",,,,,,,
"MLF_001_SC04_D01","Emergent behavior: Complex abilities that appear naturally when simple rules are repeated many times, without being directly programmed","Definition","Mentions 'emerge', 'appear', or 'arise naturally';References 'simple rules' or 'basic operations';Includes 'complex behavior' or 'abilities';Shows understanding that complexity comes from simplicity;Indicates not directly programmed",,,,,,,
"MLF_001_SC04_D02","Training process: The method of improving computer performance by repeatedly showing it examples and adjusting its internal settings based on mistakes","Definition","Mentions 'training', 'learning', or 'improving';References 'examples', 'data', or 'practice';Includes 'adjust', 'change', or 'update';Shows understanding of improvement through repetition;Indicates learning from mistakes or feedback",,,,,,,
"MLF_001_SC04_D03","Parameter optimization: Automatic fine-tuning of a computer model's internal settings to minimize errors and improve accuracy","Definition","Mentions 'parameters', 'settings', or 'values';References 'optimize', 'tune', or 'adjust';Includes 'automatic' or 'automatically';Shows understanding of improving performance;Indicates reducing errors or increasing accuracy",,,,,,,
"MLF_001_SC04_D04","Data-driven learning: An approach where computers discover patterns and rules directly from examples rather than being given hand-written instructions","Definition","Mentions 'data', 'examples', or 'information';References 'discover', 'find', or 'learn';Includes 'patterns' or 'rules';Shows understanding of learning from data;Indicates not hand-programmed or explicitly coded",,,,,,,
"MLF_001_SC04_D05","Algorithmic convergence: The process where repeated practice leads to stable, consistent performance that stops improving significantly","Definition","Mentions 'convergence', 'stable', or 'consistent';References 'repeated practice' or 'training';Includes 'stops improving' or 'plateaus';Shows understanding of reaching stable state;Indicates end of significant learning progress",,,,,,,
"MLF_001_SC05","The field started in the 1940s but has progressed exponentially with modern graphic processing units","SubConcept","Can explain the evolution from simple mechanical calculators in the 1940s to today's powerful electronic computers;Understands that parallel processing allows many calculations to happen simultaneously rather than one after another;Recognizes that graphics processing units (GPUs) were originally made for video games but are perfect for machine learning;Can describe how computational complexity measures the resources needed as problems get bigger;Shows understanding that exponential growth means rapid acceleration where capabilities double at regular intervals",,,,,,,
"MLF_001_SC05_D01","Historical computing evolution: The development from simple mechanical calculators in the 1940s to today's powerful electronic computers","Definition","Mentions '1940s', 'history', or 'development';References 'mechanical' to 'electronic' progression;Includes 'calculators' to 'computers';Shows understanding of technological progression;Indicates dramatic improvement over time",,,,,,,
"MLF_001_SC05_D02","Parallel processing: The ability to do many calculations at the same time instead of one after another, like having many workers instead of one","Definition","Mentions 'parallel', 'simultaneous', or 'same time';References 'many calculations' or 'multiple operations';Includes comparison to 'many workers' or team analogy;Shows understanding of simultaneous vs sequential;Indicates faster processing through parallelism",,,,,,,
"MLF_001_SC05_D03","Graphics Processing Units (GPUs): Special computer chips originally made for video games that can do thousands of simple math operations simultaneously","Definition","Mentions 'GPU', 'graphics card', or 'computer chip';References 'video games' or 'graphics';Includes 'thousands' and 'simultaneous';Shows understanding of original gaming purpose;Indicates many simple operations at once",,,,,,,
"MLF_001_SC05_D04","Computational complexity: A measure of how much time and computer memory is needed as problems get bigger and more difficult","Definition","Mentions 'complexity', 'difficulty', or 'requirements';References 'time', 'memory', or 'resources';Includes 'bigger problems' or 'problem size';Shows understanding of scaling challenges;Indicates relationship between problem size and resources",,,,,,,
"MLF_001_SC05_D05","Exponential growth: A pattern where something doubles in size or capability at regular intervals, leading to extremely rapid increase over time","Definition","Mentions 'exponential', 'doubles', or 'rapid growth';References 'regular intervals' or 'time periods';Includes 'extremely rapid' or 'accelerating';Shows understanding of compounding growth;Indicates dramatic increase over time",,,,,,,
"MLC_002","Categories of Machine Learning Algorithms","Concept","Can distinguish between supervised learning (using labeled data with known answers), unsupervised learning (finding patterns in unlabeled data), and semi-supervised learning (combining both approaches);Understands that reinforcement learning involves sequential decision-making where agents learn through trial and error with rewards and penalties;Recognizes that deep learning uses multi-layered neural networks to automatically discover features and handle complex, multi-dimensional data;Can explain when to use each type of learning approach based on available data and problem requirements;Shows understanding that different learning paradigms are suited for different types of problems and data availability scenarios",,,,,,,
"MLC_002_SC01","Supervised Learning involves training using 'labeled data' where algorithms learn to map input data to known output","SubConcept","Can explain that supervised learning uses information that comes with both questions and correct answers;Understands that the goal is to learn the relationship between what goes in and what should come out;Recognizes that classification involves sorting things into different categories based on their characteristics;Can describe regression as predicting specific numbers or values rather than just categories;Shows understanding that labeled data provides examples of correct input-output pairs for learning",,,,,,,
"MLC_002_SC01_D01","Labeled data: Information that comes with both the question and the correct answer already provided","Definition","Mentions 'labels', 'answers', or 'correct output';References 'input and output' or 'question and answer';Includes 'known', 'provided', or 'given';Shows understanding that both parts are available;Indicates data includes the solution",,,,,,,
"MLC_002_SC01_D02","Mapping: Learning the relationship between what goes in and what should come out","Definition","Mentions 'relationship', 'connection', or 'mapping';References 'input to output' or 'cause and effect';Includes 'learn', 'understand', or 'figure out';Shows understanding of learning connections;Indicates finding patterns between input and output",,,,,,,
"MLC_002_SC01_D03","Classification: Sorting things into different categories or groups based on their characteristics","Definition","Mentions 'classify', 'categories', or 'groups';References 'sort', 'organize', or 'divide';Includes 'characteristics', 'features', or 'properties';Shows understanding of grouping similar things;Indicates assigning items to predefined classes",,,,,,,
"MLC_002_SC01_D04","Regression: Predicting a specific number or value rather than just a category","Definition","Mentions 'predict', 'estimate', or 'calculate';References 'number', 'value', or 'amount';Includes 'continuous' or 'specific quantity';Shows understanding of numerical prediction;Indicates forecasting measurable outcomes",,,,,,,
"MLC_002_SC02","Unsupervised Learning trains on 'unlabeled data' where machines discover patterns and relationships independently","SubConcept","Can explain that unsupervised learning works with information that only shows inputs without correct answers;Understands that machines must find hidden structures and patterns without being told what to look for;Recognizes that clustering automatically groups similar items together without knowing group names in advance;Can describe association as finding items that frequently appear together or are related;Shows understanding that pattern discovery happens independently without human guidance",,,,,,,
"MLC_002_SC02_D01","Unlabeled data: Information that only shows you the input without telling you what the correct answer should be","Definition","Mentions 'no labels', 'no answers', 'unlabeled';References 'input only' or 'no correct output';Includes 'unknown', 'hidden', 'not provided';Shows understanding that answers are missing;Indicates only raw information is available",,,,,,,
"MLC_002_SC02_D02","Pattern discovery: Finding hidden structures, groups, or trends in data without being told what to look for","Definition","Mentions 'discover', 'find', 'uncover';References 'hidden patterns', 'structures', 'relationships';Includes 'without guidance' or 'independently';Shows understanding of autonomous exploration;Indicates finding unexpected connections",,,,,,,
"MLC_002_SC02_D03","Clustering: Automatically grouping similar items together without knowing the group names in advance","Definition","Mentions 'cluster', 'group', 'organize';References 'similar items' or 'like things';Includes 'automatic' or 'without knowing groups';Shows understanding of natural grouping;Indicates finding similarity-based categories",,,,,,,
"MLC_002_SC02_D04","Association: Finding items that frequently appear together or are related to each other","Definition","Mentions 'association', 'together', or 'related';References 'frequently', 'often', or 'commonly';Includes 'co-occurrence' or 'appear with';Shows understanding of relationship detection;Indicates finding items that go together",,,,,,,
"MLC_002_SC03","Semi-supervised Learning leverages both labeled and unlabeled data paradigms when datasets are incompletely labeled","SubConcept","Can explain that semi-supervised learning uses both examples with answers and examples without answers in the same process;Understands that this approach is used when you have some examples with correct answers but many without;Recognizes that this method makes efficient use of expensive human labeling by combining it with abundant unlabeled data;Can describe scenarios where labeling all data would be too costly or time-consuming;Shows understanding that combining both data types can improve learning beyond using either type alone",,,,,,,
"MLC_002_SC03_D01","Mixed data approach: Using both examples with answers and examples without answers in the same learning process","Definition","Mentions 'both types', 'mixed', or 'combination';References 'labeled and unlabeled' or 'with and without answers';Includes 'same process' or 'together';Shows understanding of hybrid approach;Indicates using all available information",,,,,,,
"MLC_002_SC03_D02","Incomplete labeling: When you have some examples with correct answers but many examples without answers","Definition","Mentions 'incomplete', 'partial', or 'some labeled';References 'missing answers' or 'not all labeled';Includes 'many without' or 'few with answers';Shows understanding of partial information;Indicates common real-world data limitation",,,,,,,
"MLC_002_SC03_D03","Resource efficiency: Making the most of expensive human labeling by combining it with abundant unlabeled data","Definition","Mentions 'expensive', 'costly', or 'limited resources';References 'human effort' or 'manual labeling';Includes 'abundant', 'plenty', or 'lots of unlabeled';Shows understanding of practical constraints;Indicates economic considerations in data preparation",,,,,,,
"MLC_002_SC04","Reinforcement Learning involves sequential decision-making where machines learn through trial and error with rewards and penalties","SubConcept","Can explain that reinforcement learning involves making a series of choices over time where each choice affects future options;Understands that learning happens by trying different actions and seeing what happens, then adjusting based on results;Recognizes that the system receives positive feedback for good actions and negative feedback for bad actions;Can describe the relationship between a learner (agent) that takes actions in a world (environment) and receives feedback;Shows understanding that the goal is to learn which actions lead to the best long-term outcomes",,,,,,,
"MLC_002_SC04_D01","Sequential decisions: Making a series of choices over time where each choice affects future options","Definition","Mentions 'sequence', 'series', or 'over time';References 'multiple decisions' or 'chain of choices';Includes 'affects future' or 'consequences';Shows understanding of connected decisions;Indicates decisions build on each other",,,,,,,
"MLC_002_SC04_D02","Trial and error: Learning by trying different actions and seeing what happens, then adjusting based on results","Definition","Mentions 'trial and error', 'try different things', or 'experiment';References 'see what happens' or 'observe results';Includes 'adjust', 'change', or 'improve';Shows understanding of learning through experience;Indicates improvement through experimentation",,,,,,,
"MLC_002_SC04_D03","Reward system: Getting positive feedback for good actions and negative feedback for bad actions","Definition","Mentions 'rewards', 'feedback', or 'consequences';References 'positive and negative' or 'good and bad';Includes 'actions', 'choices', or 'decisions';Shows understanding of feedback-driven learning;Indicates behavior modification through consequences",,,,,,,
"MLC_002_SC04_D04","Agent environment: A learner (agent) that takes actions in a world (environment) and receives feedback","Definition","Mentions 'agent', 'learner', or 'decision maker';References 'environment', 'world', or 'setting';Includes 'takes actions' or 'interacts';Shows understanding of actor-world relationship;Indicates active participation in environment",,,,,,,
"MLC_002_SC05","Deep Learning uses neural networks with multiple hidden layers to handle complex multi-dimensional data","SubConcept","Can explain that deep learning uses many stacked levels of processing units, not just a single layer;Understands that hidden layers are processing levels between input and output that transform information in complex ways;Recognizes that complex data has many dimensions, features, or intricate patterns that simple methods cannot handle;Can describe how the system discovers important characteristics in data without human specification;Shows understanding that multiple layers enable learning of increasingly sophisticated patterns",,,,,,,
"MLC_002_SC05_D01","Multiple layers: Having many stacked levels of processing units, not just a single layer","Definition","Mentions 'multiple', 'many', or 'several layers';References 'stacked', 'deep', or 'hierarchical';Includes 'levels' or 'tiers';Shows understanding of vertical structure;Indicates more than simple single-layer processing",,,,,,,
"MLC_002_SC05_D02","Hidden layers: Processing levels between the input and output that transform information in complex ways","Definition","Mentions 'hidden', 'intermediate', or 'middle layers';References 'between input and output' or 'internal processing';Includes 'transform', 'process', or 'modify';Shows understanding of internal computation;Indicates invisible processing steps",,,,,,,
"MLC_002_SC05_D03","Complex data: Information with many dimensions, features, or intricate patterns that simple methods cannot handle","Definition","Mentions 'complex', 'complicated', or 'intricate';References 'many dimensions', 'features', or 'variables';Includes 'patterns', 'relationships', or 'structures';Shows understanding of data complexity;Indicates challenging information processing needs",,,,,,,
"MLC_002_SC05_D04","Automatic feature learning: The system discovers important characteristics in data without human specification","Definition","Mentions 'automatic', 'discovers', or 'learns features';References 'without human help' or 'no manual specification';Includes 'important characteristics' or 'relevant aspects';Shows understanding of autonomous discovery;Indicates system finds patterns independently",,,,,,,
"MLD_003","Data Preparation and Feature Engineering","Concept","Can identify and address data quality issues including missing values, inconsistencies, and outliers that could interfere with machine learning;Understands how to combine information from multiple sources and create unified datasets for comprehensive analysis;Recognizes the importance of reducing unnecessary features and noise while keeping essential information that matters for the task;Can explain how to convert categorical information into numerical format that computers can process mathematically;Shows understanding of proper data splitting into training, validation, and testing sets to ensure honest evaluation of model performance",,,,,,,
"MLD_003_SC01","Data quality assessment involves analyzing for missing values, inconsistencies, and outliers","SubConcept","Can identify gaps in data where information should be present but is missing or unavailable;Understands that inconsistencies occur when the same type of information is recorded differently in different places;Recognizes outliers as data points that are unusually different from most other data points;Can describe the importance of exploring data to understand its patterns, distributions, and characteristics;Shows understanding that data quality issues must be identified and addressed before machine learning",,,,,,,
"MLD_003_SC01_D01","Missing values: Gaps in your data where information should be but isn't available","Definition","Mentions 'missing', 'gaps', or 'empty spots';References 'no data', 'blank', or 'unavailable';Includes 'should be there' or 'expected information';Shows understanding of incomplete datasets;Indicates data collection problems",,,,,,,
"MLD_003_SC01_D02","Inconsistencies: When the same type of information is recorded differently in different places","Definition","Mentions 'inconsistent', 'different formats', or 'contradictory';References 'same thing recorded differently' or 'conflicting information';Includes 'formatting problems' or 'data entry errors';Shows understanding of data quality issues;Indicates need for standardization",,,,,,,
"MLD_003_SC01_D03","Outliers: Data points that are unusually different from most other data points","Definition","Mentions 'outliers', 'unusual', or 'extreme values';References 'very different', 'doesn't fit', or 'abnormal';Includes 'most other data' or 'typical pattern';Shows understanding of exceptional cases;Indicates values that stand out from the norm",,,,,,,
"MLD_003_SC01_D04","Data exploration: Looking through your data to understand its patterns, distributions, and characteristics","Definition","Mentions 'explore', 'examine', or 'investigate';References 'patterns', 'distributions', or 'characteristics';Includes 'understand', 'get familiar', or 'learn about';Shows understanding of preliminary analysis;Indicates systematic data examination",,,,,,,
"MLD_003_SC02","Feature aggregation combines data from multiple tables or sources","SubConcept","Can explain the process of bringing together information from different databases, files, or systems;Understands how to connect related information from separate tables based on common identifiers;Recognizes the goal of creating a single, unified view of data that was previously scattered;Can describe why combining multiple data sources often provides more complete information for machine learning;Shows understanding of the challenges involved in matching and merging data from different sources",,,,,,,
"MLD_003_SC02_D01","Combining sources: Bringing together information from different databases, files, or systems","Definition","Mentions 'combine', 'merge', or 'bring together';References 'different sources', 'multiple tables', or 'various systems';Includes 'databases', 'files', or 'datasets';Shows understanding of data integration;Indicates working with multiple information sources",,,,,,,
"MLD_003_SC02_D02","Data joining: Connecting related information from separate tables based on common identifiers","Definition","Mentions 'join', 'connect', or 'link';References 'related information' or 'common identifiers';Includes 'separate tables' or 'different datasets';Shows understanding of relational connections;Indicates matching records across sources",,,,,,,
"MLD_003_SC02_D03","Information consolidation: Creating a single, unified view of data that was previously scattered","Definition","Mentions 'consolidate', 'unify', or 'single view';References 'scattered', 'fragmented', or 'separate pieces';Includes 'unified', 'complete picture', or 'together';Shows understanding of data organization;Indicates creating comprehensive datasets",,,,,,,
"MLD_003_SC03","Dimensionality reduction eliminates irrelevant features and noise","SubConcept","Can explain that having too many characteristics or variables can confuse machine learning algorithms;Understands that irrelevant information doesn't help solve the problem and may actually hurt performance;Recognizes the importance of removing random variations and errors that don't represent true patterns;Can describe techniques like Principal Component Analysis that find the most important directions of variation in data;Shows understanding that the goal is to keep only essential features that actually matter for the task",,,,,,,
"MLD_003_SC03_D01","Too many features: Having more characteristics or variables than necessary, which can confuse learning","Definition","Mentions 'too many', 'excessive', or 'overwhelming features';References 'characteristics', 'variables', or 'dimensions';Includes 'confuse', 'complicate', or 'interfere with learning';Shows understanding of feature overload;Indicates more isn't always better",,,,,,,
"MLD_003_SC03_D02","Irrelevant information: Data that doesn't help solve the problem and may actually hurt performance","Definition","Mentions 'irrelevant', 'unhelpful', 'doesn't matter';References 'doesn't help', 'not useful', or 'unrelated';Includes 'hurt performance' or 'makes things worse';Shows understanding of information quality;Indicates need for selective data use",,,,,,,
"MLD_003_SC03_D03","Noise reduction: Removing random variations or errors that don't represent true patterns","Definition","Mentions 'noise', 'random variations', or 'errors';References 'remove', 'filter out', or 'clean';Includes 'true patterns' or 'real signal';Shows understanding of signal vs noise;Indicates improving data quality",,,,,,,
"MLD_003_SC03_D04","Principal Component Analysis: A technique that finds the most important directions of variation in data","Definition","Mentions 'PCA', 'principal components', or 'main directions';References 'most important variation' or 'key patterns';Includes 'reduce dimensions' or 'compress information';Shows understanding of dimensionality reduction technique;Indicates finding essential data structure",,,,,,,
"MLD_003_SC04","Feature encoding converts categorical variables to numerical for ML model consumption","SubConcept","Can explain that categorical variables represent categories or groups rather than numbers;Understands the need to turn category names into numbers that computers can work with mathematically;Recognizes that one-hot encoding creates separate yes/no columns for each category instead of using arbitrary numbers;Can describe why using arbitrary numbers for categories would create misleading mathematical relationships;Shows understanding that proper encoding preserves the categorical nature of the data while making it computer-readable",,,,,,,
"MLD_003_SC04_D01","Categorical variables: Information that represents categories or groups rather than numbers","Definition","Mentions 'categories', 'groups', or 'types';References 'not numbers', 'text labels', or 'names';Includes examples like 'colors', 'countries', or 'yes/no';Shows understanding of non-numerical data;Indicates descriptive rather than quantitative information",,,,,,,
"MLD_003_SC04_D02","Numerical conversion: Turning category names into numbers that computers can work with mathematically","Definition","Mentions 'convert', 'turn into numbers', or 'encode';References 'mathematical operations' or 'computer processing';Includes 'from text to numbers' or 'numerical representation';Shows understanding of computer requirements;Indicates transformation for computational use",,,,,,,
"MLD_003_SC04_D03","One-hot encoding: Creating separate yes/no columns for each category instead of using arbitrary numbers","Definition","Mentions 'one-hot', 'separate columns', or 'binary encoding';References 'yes/no', 'on/off', or '1/0 for each category';Includes 'avoid arbitrary numbers' or 'no false ordering';Shows understanding of proper categorical encoding;Indicates preventing misleading numerical relationships",,,,,,,
"MLD_003_SC05","Data splitting divides information into training, validation, and testing sets","SubConcept","Can explain that the training set is the portion used to teach the model patterns and relationships;Understands that validation data is used to tune and adjust the model during development without cheating;Recognizes that testing data is fresh information the model has never seen, used for final honest evaluation;Can describe the common 80/20 split where most data is used for training and smaller portion for testing;Shows understanding that separate datasets are essential for honest assessment of model performance",,,,,,,
"MLD_003_SC05_D01","Training set: The portion of data used to teach the model patterns and relationships","Definition","Mentions 'training', 'teach', or 'learn from';References 'patterns', 'relationships', or 'examples';Includes 'largest portion' or 'most of the data';Shows understanding of learning phase;Indicates primary dataset for model development",,,,,,,
"MLD_003_SC05_D02","Validation set: Data used to tune and adjust the model during development without cheating","Definition","Mentions 'validation', 'tuning', or 'adjustment';References 'during development' or 'while building';Includes 'without cheating' or 'fair evaluation';Shows understanding of honest assessment;Indicates separate data for model improvement",,,,,,,
"MLD_003_SC05_D03","Testing set: Fresh data that the model has never seen, used for final honest evaluation","Definition","Mentions 'testing', 'never seen', or 'fresh data';References 'final evaluation' or 'honest assessment';Includes 'completely separate' or 'held back';Shows understanding of unbiased evaluation;Indicates true performance measurement",,,,,,,
"MLD_003_SC05_D04","80/20 split: Common practice of using 80% of data for training and 20% for testing","Definition","Mentions '80/20', 'eighty-twenty', or specific percentages';References 'common practice' or 'typical split';Includes 'most for training' or 'smaller for testing';Shows understanding of standard proportions;Indicates balanced approach to data allocation",,,,,,,
"MLM_004","Model Selection and Performance Evaluation","Concept","Can explain that model selection requires experimental testing of different approaches because there's no universal best model for all problems;Understands that ensemble methods combine multiple weak models to create stronger overall predictions through collective decision-making;Recognizes that performance evaluation must match the problem type, using accuracy and precision for classification versus error measures for regression;Can describe how different models suit different dataset characteristics and computational constraints;Shows understanding that proper evaluation requires systematic comparison and consideration of both performance and practical implementation factors",,,,,,,
"MLM_004_SC01","Model selection is often experimental to find the best fit for specific problems and datasets","SubConcept","Can explain that trying different models is necessary because there's no way to know in advance which will work best;Understands that different types of problems need different types of models to solve them effectively;Recognizes that dataset characteristics like size and complexity affect which model will perform best;Can describe the process of systematically comparing multiple models to find the optimal choice;Shows understanding that model selection requires empirical testing rather than theoretical prediction",,,,,,,
"MLM_004_SC01_D01","Experimental approach: Trying different models to see which one works best, rather than knowing in advance","Definition","Mentions 'try different', 'experiment', or 'test various';References 'see which works best' or 'compare performance';Includes 'don't know in advance' or 'trial and error';Shows understanding of empirical testing;Indicates systematic comparison process",,,,,,,
"MLM_004_SC01_D02","Problem-specific fitting: Different types of problems need different types of models to solve them well","Definition","Mentions 'different problems', 'specific needs', or 'type of task';References 'different models' or 'various approaches';Includes 'best fit' or 'appropriate choice';Shows understanding of matching models to problems;Indicates no universal best model",,,,,,,
"MLM_004_SC01_D03","Dataset characteristics: The size, complexity, and nature of your data affects which model will work best","Definition","Mentions 'dataset size', 'data complexity', or 'data characteristics';References 'affects model choice' or 'influences selection';Includes 'small vs large data' or 'simple vs complex';Shows understanding of data-model relationship;Indicates data properties guide model choice",,,,,,,
"MLM_004_SC02","Ensemble learning combines multiple weak models simultaneously for better predictions","SubConcept","Can explain that ensemble methods use several different models together instead of relying on just one;Understands that individual models may be weak learners that are only slightly better than random guessing;Recognizes that when combined, weak models can create much stronger overall predictions;Can describe how ensemble methods like voting or averaging combine individual model predictions;Shows understanding that collective decision-making often outperforms individual model predictions",,,,,,,
"MLM_004_SC02_D01","Multiple models: Using several different models together instead of relying on just one","Definition","Mentions 'multiple', 'several', or 'many models';References 'together', 'combined', or 'at the same time';Includes 'instead of one' or 'not just single';Shows understanding of collective approach;Indicates team-based modeling",,,,,,,
"MLM_004_SC02_D02","Weak learners: Individual models that are only slightly better than random guessing","Definition","Mentions 'weak', 'simple', or 'basic models';References 'slightly better than random' or 'not very accurate alone';Includes 'individual performance' or 'on their own';Shows understanding of limited individual capability;Indicates models with modest individual performance",,,,,,,
"MLM_004_SC02_D03","Collective strength: When combined, weak models can create a much stronger overall prediction","Definition","Mentions 'combined strength', 'together stronger', or 'collective power';References 'much better together' or 'stronger overall';Includes 'team effect' or 'synergy';Shows understanding of emergent capability;Indicates whole greater than sum of parts",,,,,,,
"MLM_004_SC03","Performance metrics depend on problem type: classification uses accuracy/precision/recall, regression uses error measures","SubConcept","Can explain that classification metrics measure how well a model sorts things into correct categories;Understands that regression metrics measure how close predicted numbers are to actual numbers;Recognizes that accuracy shows the percentage of predictions that are completely correct;Can describe that error measures show how far off predictions are from reality;Shows understanding that different problem types require different ways of measuring success",,,,,,,
"MLM_004_SC03_D01","Classification metrics: Ways to measure how well a model sorts things into the correct categories","Definition","Mentions 'classification', 'categories', or 'sorting into groups';References 'accuracy', 'precision', 'recall', or 'correct predictions';Includes 'how many right' or 'percentage correct';Shows understanding of categorical evaluation;Indicates measuring classification success",,,,,,,
"MLM_004_SC03_D02","Regression metrics: Ways to measure how close predicted numbers are to the actual numbers","Definition","Mentions 'regression', 'predicting numbers', or 'numerical values';References 'how close', 'error', or 'difference from actual';Includes 'predicted vs actual' or 'distance from truth';Shows understanding of numerical evaluation;Indicates measuring prediction accuracy for numbers",,,,,,,
"MLM_004_SC03_D03","Accuracy: The percentage of predictions that are completely correct","Definition","Mentions 'accuracy', 'percentage correct', or 'fraction right';References 'all predictions' or 'overall performance';Includes 'completely correct' or 'exactly right';Shows understanding of overall success rate;Indicates simple correctness measure",,,,,,,
"MLM_004_SC03_D04","Error measures: Numbers that show how far off the predictions are from reality","Definition","Mentions 'error', 'difference', or 'how far off';References 'from reality', 'actual values', or 'true answers';Includes 'distance', 'gap', or 'deviation';Shows understanding of prediction quality;Indicates measuring wrongness magnitude",,,,,,,
"MLB_005","Overfitting, Underfitting, and Model Balance","Concept","Can explain that overfitting occurs when models memorize training examples and noise instead of learning generalizable patterns, causing poor performance on new data;Understands that underfitting happens when models are too simple to capture important patterns and relationships, resulting in consistently poor performance;Recognizes that balanced models achieve the right level of complexity to capture real patterns without memorizing irrelevant details;Can describe the bias-variance tradeoff and how it affects model performance on both training and testing data;Shows understanding that finding optimal model complexity is crucial for good generalization to new, unseen examples",,,,,,,
"MLB_005_SC01","Overfitting occurs when models learn underlying patterns plus noise, performing poorly on new data","SubConcept","Can explain that overfitting happens when a model remembers specific training examples instead of learning general patterns;Understands that models can pick up random variations and errors as if they were important patterns;Recognizes that overfitted models work well on training data but fail on new, unseen examples;Can describe how overfitting results from the model being too complex for the amount of available data;Shows understanding that overfitting prevents models from generalizing to new situations",,,,,,,
"MLB_005_SC01_D01","Memorizing training data: When a model remembers specific examples instead of learning general patterns","Definition","Mentions 'memorize', 'remember specific examples', or 'learn by heart';References 'instead of patterns' or 'not generalizing';Includes 'training data' or 'specific cases';Shows understanding of rote learning problem;Indicates lack of true pattern recognition",,,,,,,
"MLB_005_SC01_D02","Learning noise: Picking up random variations and errors as if they were important patterns","Definition","Mentions 'noise', 'random variations', or 'errors';References 'as if important' or 'treating as patterns';Includes 'not real patterns' or 'misleading information';Shows understanding of signal vs noise confusion;Indicates learning irrelevant details",,,,,,,
"MLB_005_SC01_D03","Poor generalization: Working well on training data but failing on new, unseen examples","Definition","Mentions 'poor generalization', 'doesn't work on new data', or 'fails on unseen';References 'good on training' but 'bad on testing';Includes 'new examples' or 'fresh data';Shows understanding of transfer failure;Indicates limited applicability beyond training",,,,,,,
"MLB_005_SC02","Underfitting happens when models are too simple to capture data complexity, showing high bias","SubConcept","Can explain that underfitting occurs when a model lacks the complexity needed to understand the data's patterns;Understands that simple models can fail to detect important relationships and trends that exist in the data;Recognizes that high bias means consistently making the same type of error due to oversimplified assumptions;Can describe how underfitted models perform poorly on both training and testing data;Shows understanding that underfitting results from choosing a model that is too basic for the problem",,,,,,,
"MLB_005_SC02_D01","Too simple model: A model that lacks the complexity needed to understand the data's patterns","Definition","Mentions 'too simple', 'not complex enough', or 'insufficient capacity';References 'can't understand patterns' or 'misses relationships';Includes 'lacks complexity' or 'oversimplified';Shows understanding of inadequate model capacity;Indicates model limitations relative to problem",,,,,,,
"MLB_005_SC02_D02","Missing patterns: Failing to detect important relationships and trends that exist in the data","Definition","Mentions 'missing patterns', 'fails to detect', or 'overlooks relationships';References 'important trends' or 'real connections';Includes 'exist in data' or 'are there but unseen';Shows understanding of pattern blindness;Indicates inability to capture data structure",,,,,,,
"MLB_005_SC02_D03","High bias: Consistently making the same type of error due to oversimplified assumptions","Definition","Mentions 'bias', 'systematic error', or 'consistent mistakes';References 'same type of error' or 'repeated problems';Includes 'oversimplified assumptions' or 'wrong approach';Shows understanding of systematic failure;Indicates predictable error patterns",,,,,,,
"MLB_005_SC03","Balanced models strike the right balance between bias and variance for accurate predictions","SubConcept","Can explain that balanced models have just enough complexity to capture patterns without memorizing noise;Understands that the bias-variance tradeoff involves balancing systematic errors and sensitivity to data variations;Recognizes that good generalization means performing well on both training data and completely new examples;Can describe how finding the right model complexity is key to achieving good performance;Shows understanding that the goal is to avoid both underfitting and overfitting",,,,,,,
"MLB_005_SC03_D01","Right complexity level: Having just enough model complexity to capture patterns without memorizing noise","Definition","Mentions 'right complexity', 'just enough', or 'balanced approach';References 'capture patterns' and 'avoid memorizing';Includes 'without noise' or 'not too simple/complex';Shows understanding of optimal complexity;Indicates goldilocks principle in modeling",,,,,,,
"MLB_005_SC03_D02","Bias-variance tradeoff: Balancing between systematic errors and sensitivity to data variations","Definition","Mentions 'bias-variance', 'tradeoff', or 'balance';References 'systematic errors' and 'data sensitivity';Includes 'both problems' or 'neither extreme';Shows understanding of competing concerns;Indicates need to optimize both aspects",,,,,,,
"MLB_005_SC03_D03","Good generalization: Performing well on both training data and completely new examples","Definition","Mentions 'good generalization', 'works on new data', or 'transfers well';References 'both training and testing' or 'seen and unseen';Includes 'consistent performance' or 'reliable predictions';Shows understanding of robust performance;Indicates successful pattern learning",,,,,,,
"MLN_006","Neural Networks and Deep Learning Architecture","Concept","Can explain how neural networks are organized with interconnected processing units arranged in input, hidden, and output layers that pass information forward;Understands that backpropagation works backwards from prediction errors to adjust connection strengths throughout the network for iterative learning;Recognizes that deep networks can capture complex, non-linear relationships but require large datasets and significant computational resources;Can describe how information flows through multiple layers, with each layer transforming data in increasingly sophisticated ways;Shows understanding that neural network architecture must be designed to match problem complexity and available computational constraints",,,,,,,
"MLN_006_SC01","Neural networks consist of interconnected nodes with input, hidden, and output layers","SubConcept","Can explain that neural networks are made of simple processing units connected to pass information between them;Understands that the input layer receives raw data or information to be processed;Recognizes that hidden layers are middle layers that transform and process information between input and output;Can describe that the output layer produces the final answer or prediction;Shows understanding that information flows through the network from input to output through interconnected nodes",,,,,,,
"MLN_006_SC01_D01","Interconnected nodes: Simple processing units that are connected to each other to pass information","Definition","Mentions 'connected', 'linked', or 'networked';References 'nodes', 'units', or 'neurons';Includes 'pass information' or 'send signals';Shows understanding of network structure;Indicates connected processing elements",,,,,,,
"MLN_006_SC01_D02","Input layer: The first layer that receives the raw data or information to be processed","Definition","Mentions 'input layer', 'first layer', or 'receives data';References 'raw data', 'original information', or 'starting point';Includes 'where data enters' or 'beginning of process';Shows understanding of data entry point;Indicates initial processing stage",,,,,,,
"MLN_006_SC01_D03","Hidden layers: Middle layers that transform and process information between input and output","Definition","Mentions 'hidden layers', 'middle layers', or 'between input and output';References 'transform', 'process', or 'modify information';Includes 'internal processing' or 'invisible work';Shows understanding of intermediate computation;Indicates where main processing occurs",,,,,,,
"MLN_006_SC01_D04","Output layer: The final layer that produces the answer or prediction","Definition","Mentions 'output layer', 'final layer', or 'produces answer';References 'prediction', 'result', or 'conclusion';Includes 'end of process' or 'where answer comes out';Shows understanding of result generation;Indicates final processing stage",,,,,,,
"MLN_006_SC02","Back propagation algorithms minimize error between predicted and actual outputs through iterative learning","SubConcept","Can explain that backpropagation measures the difference between what the model predicted and what actually happened;Understands that the algorithm works backwards from the error to find what needs fixing in the network;Recognizes that weight adjustment changes the strength of connections between nodes to reduce future errors;Can describe how this process repeats many times to gradually improve the network's performance;Shows understanding that backpropagation is how neural networks learn from their mistakes",,,,,,,
"MLN_006_SC02_D01","Error calculation: Measuring the difference between what the model predicted and what actually happened","Definition","Mentions 'error', 'difference', or 'gap';References 'predicted vs actual' or 'expected vs real';Includes 'measuring', 'calculating', or 'comparing';Shows understanding of performance measurement;Indicates quantifying prediction quality",,,,,,,
"MLN_006_SC02_D02","Working backwards: Starting from the error and tracing back through the network to find what needs fixing","Definition","Mentions 'backwards', 'reverse direction', or 'trace back';References 'from error' or 'starting from mistake';Includes 'find what needs fixing' or 'identify problems';Shows understanding of error attribution;Indicates reverse flow of correction information",,,,,,,
"MLN_006_SC02_D03","Weight adjustment: Changing the strength of connections between nodes to reduce future errors","Definition","Mentions 'weights', 'connections', or 'strength';References 'adjust', 'change', or 'modify';Includes 'reduce errors' or 'improve performance';Shows understanding of learning mechanism;Indicates parameter modification for improvement",,,,,,,
"MLN_006_SC03","Deep networks capture non-linear relationships but require large datasets and computational resources","SubConcept","Can explain that non-linear relationships are complex patterns where small changes can have big effects or relationships curve and twist;Understands that deep networks need many examples to learn effectively without memorizing specific cases;Recognizes that deep networks require powerful computers and lots of processing time;Can describe why deep networks are better at handling complex, multi-dimensional data than simpler models;Shows understanding that the depth of networks enables learning of sophisticated, hierarchical patterns",,,,,,,
"MLN_006_SC03_D01","Non-linear relationships: Complex patterns where small changes can have big effects, or where relationships curve and twist","Definition","Mentions 'non-linear', 'complex patterns', or 'curved relationships';References 'not straight lines' or 'twisting connections';Includes 'small changes, big effects' or 'complicated interactions';Shows understanding of complex data relationships;Indicates ability to model sophisticated patterns",,,,,,,
"MLN_006_SC03_D02","Large dataset requirement: Deep networks need many examples to learn effectively without memorizing","Definition","Mentions 'need many examples', 'large datasets', or 'lots of data';References 'learn effectively' or 'work properly';Includes 'without memorizing' or 'avoid overfitting';Shows understanding of data volume requirements;Indicates scaling needs for deep learning",,,,,,,
"MLN_006_SC03_D03","Computational intensity: Deep networks require powerful computers and lots of processing time","Definition","Mentions 'powerful computers', 'lots of processing', or 'computationally intensive';References 'processing time', 'computational resources', or 'computing power';Includes 'expensive to run' or 'resource hungry';Shows understanding of computational demands;Indicates hardware and time requirements",,,,,,,
"MLP_007","Performance Metrics and Model Evaluation","Concept","Can explain different classification metrics (accuracy, precision, recall, F1-score) and when each is most appropriate for evaluating model performance;Understands that cross-validation provides more reliable performance estimates by testing models on multiple different data arrangements;Recognizes that metric selection depends on the specific goals and constraints of the problem being solved;Can describe how robust evaluation methods help avoid misleading results from favorable data splits or chance;Shows understanding that proper evaluation is essential for determining whether a model will work reliably in real-world applications",,,,,,,
"MLP_007_SC01","Classification metrics include accuracy, precision, recall, F1-score, and Area Under ROC Curve","SubConcept","Can explain that accuracy is the percentage of all predictions that were correct;Understands that precision measures how many predicted positive cases actually were positive;Recognizes that recall measures how many actual positive cases the model successfully found;Can describe that F1-score is a single number that balances both precision and recall together;Shows understanding that different metrics focus on different aspects of classification performance",,,,,,,
"MLP_007_SC01_D01","Accuracy: The percentage of all predictions that were correct","Definition","Mentions 'accuracy', 'percentage correct', or 'fraction right';References 'all predictions' or 'total attempts';Includes 'overall correctness' or 'general performance';Shows understanding of simple success rate;Indicates basic correctness measurement",,,,,,,
"MLP_007_SC01_D02","Precision: Of all the items predicted as positive, how many actually were positive","Definition","Mentions 'precision', 'predicted positive', or 'accuracy of positive predictions';References 'how many actually were' or 'true positives among predictions';Includes 'quality of positive calls' or 'avoiding false alarms';Shows understanding of prediction quality focus;Indicates concern with false positive reduction",,,,,,,
"MLP_007_SC01_D03","Recall: Of all the actual positive items, how many did the model successfully find","Definition","Mentions 'recall', 'sensitivity', or 'found actual positives';References 'all actual positives' or 'everything that was really positive';Includes 'successfully find' or 'catch all cases';Shows understanding of detection completeness;Indicates concern with missing positive cases",,,,,,,
"MLP_007_SC01_D04","F1-score: A single number that balances both precision and recall together","Definition","Mentions 'F1-score', 'balance precision and recall', or 'combines both';References 'single number' or 'overall measure';Includes 'harmonic mean' or 'balanced metric';Shows understanding of combined measurement;Indicates trade-off between precision and recall",,,,,,,
"MLP_007_SC02","Cross-validation provides robust assessment of model performance across different data subsets","SubConcept","Can explain that cross-validation divides data into different training and testing combinations multiple times;Understands that this provides a more reliable estimate of performance by testing on multiple data arrangements;Recognizes that cross-validation helps avoid situations where the model looks good just because of favorable data division;Can describe how multiple evaluations give a better sense of how the model will perform on new data;Shows understanding that cross-validation reduces the impact of lucky or unlucky data splits",,,,,,,
"MLP_007_SC02_D01","Multiple data splits: Dividing data into different training and testing combinations multiple times","Definition","Mentions 'multiple splits', 'different combinations', or 'various divisions';References 'training and testing' or 'different sets';Includes 'multiple times' or 'repeated process';Shows understanding of varied evaluation;Indicates systematic testing approach",,,,,,,
"MLP_007_SC02_D02","Robust evaluation: Getting a more reliable estimate of performance by testing on multiple data arrangements","Definition","Mentions 'robust', 'reliable', or 'more trustworthy';References 'multiple arrangements' or 'different data splits';Includes 'better estimate' or 'more accurate assessment';Shows understanding of evaluation reliability;Indicates improved confidence in results",,,,,,,
"MLP_007_SC02_D03","Avoiding lucky splits: Preventing situations where model looks good just because of favorable data division","Definition","Mentions 'avoid lucky splits', 'prevent favorable division', or 'not just chance';References 'looks good by accident' or 'misleading results';Includes 'fair evaluation' or 'honest assessment';Shows understanding of evaluation bias;Indicates need for representative testing",,,,,,,
"MLH_008","Healthcare Application Considerations","Concept","Can distinguish between predicting who will develop diseases versus predicting outcomes for patients who already have diseases, and how this affects data requirements;Understands that medical expertise is essential for selecting relevant features and interpreting AI results in meaningful clinical terms;Recognizes the critical trade-off between model complexity and interpretability in healthcare, where understanding reasoning may be more important than maximum accuracy;Can explain why healthcare AI applications require special consideration due to life-and-death consequences of medical decisions;Shows understanding that successful healthcare AI requires collaboration between data scientists and medical professionals throughout development and implementation",,,,,,,
"MLH_008_SC01","Problem definition must distinguish between predicting disease occurrence vs predicting adverse outcomes","SubConcept","Can explain that disease prediction tries to determine who will develop a disease before symptoms appear;Understands that outcome prediction forecasts what will happen to patients who already have a disease;Recognizes that each type of prediction requires different information and approaches;Can describe examples of disease prediction (who will get diabetes) versus outcome prediction (how severe will their diabetes become);Shows understanding that the choice between these affects what data is needed and how success is measured",,,,,,,
"MLH_008_SC01_D01","Disease prediction: Trying to determine who will develop a disease before symptoms appear","Definition","Mentions 'disease prediction', 'who will develop', or 'before symptoms';References 'early detection' or 'preventive identification';Includes 'risk assessment' or 'likelihood of disease';Shows understanding of predictive healthcare;Indicates focus on disease development",,,,,,,
"MLH_008_SC01_D02","Outcome prediction: Forecasting what will happen to patients who already have a disease","Definition","Mentions 'outcome prediction', 'what will happen', or 'already have disease';References 'prognosis', 'course of illness', or 'treatment results';Includes 'complications', 'recovery', or 'disease progression';Shows understanding of prognostic healthcare;Indicates focus on disease consequences",,,,,,,
"MLH_008_SC01_D03","Different data needs: Each type of prediction requires different information and approaches","Definition","Mentions 'different data', 'various information', or 'distinct approaches';References 'depends on goal' or 'specific to prediction type';Includes 'different requirements' or 'unique needs';Shows understanding of task-specific requirements;Indicates tailored methodology needs",,,,,,,
"MLH_008_SC02","Clinical domain knowledge is crucial for feature selection and interpretation of results","SubConcept","Can explain that medical expertise involves understanding how diseases work, what symptoms mean, and how treatments affect patients;Understands that clinical knowledge guides selection of which medical measurements and tests are actually important for specific conditions;Recognizes that interpreting results requires understanding what model predictions mean in real medical terms and patient care;Can describe why healthcare professionals must be involved in choosing relevant features and validating results;Shows understanding that AI results must be translated into actionable medical insights",,,,,,,
"MLH_008_SC02_D01","Medical expertise: Understanding how diseases work, what symptoms mean, and how treatments affect patients","Definition","Mentions 'medical expertise', 'clinical knowledge', or 'healthcare understanding';References 'how diseases work' or 'what symptoms mean';Includes 'treatment effects' or 'patient care';Shows understanding of specialized medical knowledge;Indicates importance of healthcare expertise",,,,,,,
"MLH_008_SC02_D02","Feature selection guidance: Knowing which medical measurements and tests are actually important for specific conditions","Definition","Mentions 'feature selection', 'important measurements', or 'relevant tests';References 'medical knowledge guides choice' or 'clinical relevance';Includes 'specific conditions' or 'disease-relevant factors';Shows understanding of informed data selection;Indicates domain expertise in variable choice",,,,,,,
"MLH_008_SC02_D03","Result interpretation: Understanding what model predictions mean in real medical terms and patient care","Definition","Mentions 'result interpretation', 'medical meaning', or 'clinical significance';References 'patient care', 'treatment decisions', or 'real-world application';Includes 'practical implications' or 'actionable insights';Shows understanding of clinical translation;Indicates bridging AI results to medical practice",,,,,,,
"MLH_008_SC03","Model interpretability vs complexity trade-off is critical in medical applications","SubConcept","Can explain that interpretability means being able to understand and explain why the model made a specific prediction;Understands that healthcare decisions can affect patient lives, so understanding reasoning is crucial;Recognizes that sometimes simpler, less accurate models are chosen because they can be understood and trusted;Can describe why doctors need to understand how AI systems reach their conclusions;Shows understanding that in healthcare, explainability may be more important than maximum accuracy",,,,,,,
"MLH_008_SC03_D01","Interpretability: Being able to understand and explain why the model made a specific prediction","Definition","Mentions 'interpretability', 'explainable', or 'understand why';References 'model reasoning' or 'prediction explanation';Includes 'transparent decisions' or 'clear logic';Shows understanding of model transparency;Indicates need for explainable AI",,,,,,,
"MLH_008_SC03_D02","Medical decision stakes: Healthcare decisions can affect patient lives, so understanding reasoning is crucial","Definition","Mentions 'patient lives', 'high stakes', or 'life and death';References 'healthcare decisions' or 'medical consequences';Includes 'crucial understanding' or 'must explain';Shows understanding of medical responsibility;Indicates serious consequences of decisions",,,,,,,
"MLH_008_SC03_D03","Complexity sacrifice: Sometimes accepting simpler, less accurate models because they can be understood and trusted","Definition","Mentions 'sacrifice complexity', 'simpler models', or 'trade accuracy for understanding';References 'can be understood' or 'trusted by doctors';Includes 'acceptable trade-off' or 'practical choice';Shows understanding of practical constraints;Indicates balancing performance with usability",,,,,,,
"MLO_009","Common ML Models and Their Applications","Concept","Can explain the strengths and limitations of linear regression models, including their simplicity, interpretability, and assumption of proportional relationships;Understands how decision trees work through yes/no questions in branching patterns, their ability to handle mixed data types, and their tendency to overfit;Recognizes that random forests improve upon single decision trees by combining multiple trees through voting to reduce overfitting and increase robustness;Can describe when to choose each model type based on problem requirements, data characteristics, and interpretability needs;Shows understanding that different models represent different trade-offs between accuracy, interpretability, and computational requirements",,,,,,,
"MLO_009_SC01","Linear/Logistic Regression: Simple, interpretable models for basic prediction tasks","SubConcept","Can explain that linear regression assumes changes in input lead to proportional changes in output;Understands that these models are easy to interpret because you can see which factors are most important and how much they matter;Recognizes that linear models have limited complexity and work well for simple problems but struggle with complex patterns;Can describe when linear models are appropriate versus when more complex models are needed;Shows understanding that simplicity and interpretability are the main advantages of linear approaches",,,,,,,
"MLO_009_SC01_D01","Linear relationships: Assuming that changes in input lead to proportional changes in output","Definition","Mentions 'linear', 'straight line', or 'proportional';References 'direct relationship' or 'constant rate of change';Includes 'simple relationship' or 'predictable pattern';Shows understanding of linear assumptions;Indicates straightforward input-output mapping",,,,,,,
"MLO_009_SC01_D02","Easy interpretation: You can easily see which factors are most important and how much they matter","Definition","Mentions 'easy interpretation', 'clear factors', or 'see importance';References 'which matter most' or 'how much influence';Includes 'transparent' or 'understandable';Shows understanding of model transparency;Indicates accessible reasoning",,,,,,,
"MLO_009_SC01_D03","Limited complexity: Works well for simple problems but struggles with complex patterns","Definition","Mentions 'limited complexity', 'simple problems', or 'basic patterns';References 'struggles with complex' or 'not for complicated data';Includes 'works well for simple' or 'limited capability';Shows understanding of model limitations;Indicates scope restrictions",,,,,,,
"MLO_009_SC02","Decision Trees: Easy to understand, handle mixed data types but prone to overfitting","SubConcept","Can explain that decision trees make choices by asking a series of yes/no questions in a branching pattern;Understands that trees can work with both numbers and categories without special preparation;Recognizes that decision trees have a tendency to overfit by becoming too specific to training data;Can describe how tree structures make the decision process transparent and easy to follow;Shows understanding that trees balance interpretability with reasonable performance on many problems",,,,,,,
"MLO_009_SC02_D01","Tree-like decisions: Making choices by asking a series of yes/no questions in a branching pattern","Definition","Mentions 'tree', 'branches', or 'yes/no questions';References 'series of decisions' or 'step-by-step choices';Includes 'branching pattern' or 'flowchart-like';Shows understanding of decision structure;Indicates hierarchical choice process",,,,,,,
"MLO_009_SC02_D02","Mixed data handling: Can work with both numbers and categories without special preparation","Definition","Mentions 'mixed data', 'numbers and categories', or 'different types';References 'without special preparation' or 'handles naturally';Includes 'flexible input' or 'various data types';Shows understanding of data versatility;Indicates broad applicability",,,,,,,
"MLO_009_SC02_D03","Overfitting tendency: Can become too specific to training data, creating overly complex trees","Definition","Mentions 'overfitting', 'too specific', or 'overly complex';References 'training data memorization' or 'too detailed';Includes 'complex trees' or 'too many branches';Shows understanding of model weakness;Indicates need for complexity control",,,,,,,
"MLO_009_SC03","Random Forest: Ensemble method combining multiple decision trees to reduce overfitting","SubConcept","Can explain that random forest creates many different decision trees instead of just one;Understands that each tree makes a prediction, then the final answer is based on majority vote;Recognizes that individual trees might overfit, but together they balance each other out;Can describe how combining many trees reduces the impact of any single tree's errors;Shows understanding that ensemble methods often perform better than individual models",,,,,,,
"MLO_009_SC03_D01","Multiple trees: Creating many different decision trees instead of just one","Definition","Mentions 'multiple trees', 'many trees', or 'forest of trees';References 'instead of one' or 'collection of trees';Includes 'ensemble' or 'group approach';Shows understanding of collective modeling;Indicates multiple model approach",,,,,,,
"MLO_009_SC03_D02","Voting system: Each tree makes a prediction, then the final answer is based on majority vote","Definition","Mentions 'voting', 'majority decision', or 'trees vote';References 'each tree predicts' or 'combine predictions';Includes 'final answer' or 'democratic decision';Shows understanding of consensus mechanism;Indicates aggregated decision making",,,,,,,
"MLO_009_SC03_D03","Reduced overfitting: Individual trees might overfit, but together they balance each other out","Definition","Mentions 'reduced overfitting', 'balance each other', or 'cancel out errors';References 'individual vs group' or 'collective stability';Includes 'more robust' or 'better generalization';Shows understanding of ensemble benefit;Indicates error compensation mechanism",,,,,,,
"MLW_010","Practical Implementation Workflow","Concept","Can identify and categorize machine learning problems as classification, regression, or clustering based on the type of output or goal desired;Understands that hyperparameter tuning involves systematically adjusting algorithm settings that are not learned from data to optimize performance;Recognizes the importance of thorough documentation and reproducibility for scientific validity and allowing others to verify and build upon work;Can describe the complete workflow from problem definition through data preparation, model training, evaluation, and deployment;Shows understanding that successful machine learning projects require careful planning, systematic execution, and transparent reporting of methods and results",,,,,,,
"MLW_010_SC01","Problem characterization determines whether it's classification, regression, or clustering","SubConcept","Can explain that problem characterization involves figuring out what kind of answer you're trying to get from your data;Understands that classification problems involve sorting things into categories or groups;Recognizes that regression problems involve predicting specific numbers or measurements;Can describe clustering problems as finding hidden groups in data without knowing what groups exist;Shows understanding that the problem type determines which machine learning approaches are appropriate",,,,,,,
"MLW_010_SC01_D01","Problem type identification: Figuring out what kind of answer you're trying to get from your data","Definition","Mentions 'problem type', 'kind of answer', or 'what you want to find';References 'classification, regression, clustering' or 'different approaches';Includes 'depends on goal' or 'determines method';Shows understanding of problem taxonomy;Indicates need to categorize before solving",,,,,,,
"MLW_010_SC01_D02","Classification problems: When you want to sort things into categories or groups","Definition","Mentions 'classification', 'categories', or 'groups';References 'sort things' or 'assign labels';Includes 'which type' or 'what category';Shows understanding of categorization tasks;Indicates discrete outcome prediction",,,,,,,
"MLW_010_SC01_D03","Regression problems: When you want to predict a specific number or measurement","Definition","Mentions 'regression', 'predict number', or 'specific measurement';References 'how much' or 'what value';Includes 'continuous prediction' or 'numerical output';Shows understanding of numerical prediction;Indicates quantitative outcome forecasting",,,,,,,
"MLW_010_SC01_D04","Clustering problems: When you want to find hidden groups in data without knowing what groups exist","Definition","Mentions 'clustering', 'hidden groups', or 'unknown patterns';References 'without knowing groups' or 'discover structure';Includes 'natural groupings' or 'find similarities';Shows understanding of unsupervised grouping;Indicates exploratory data analysis",,,,,,,
"MLW_010_SC02","Hyperparameter tuning optimizes model configuration variables external to the dataset","SubConcept","Can explain that hyperparameters are settings that control how the learning algorithm behaves, not learned from data;Understands that tuning involves systematically trying different settings to find the combination that works best;Recognizes that these settings are chosen by the data scientist, not discovered by the algorithm;Can describe how hyperparameter tuning aims to get the best possible results on validation data;Shows understanding that proper tuning can significantly improve model performance",,,,,,,
"MLW_010_SC02_D01","Hyperparameters: Settings that control how the learning algorithm behaves, not learned from data","Definition","Mentions 'hyperparameters', 'settings', or 'configuration';References 'control behavior' or 'algorithm settings';Includes 'not learned from data' or 'external to dataset';Shows understanding of model configuration;Indicates algorithmic control parameters",,,,,,,
"MLW_010_SC02_D02","Tuning process: Systematically trying different settings to find the combination that works best","Definition","Mentions 'tuning', 'trying different settings', or 'optimization';References 'systematically' or 'methodical approach';Includes 'find best combination' or 'optimal performance';Shows understanding of systematic optimization;Indicates iterative improvement process",,,,,,,
"MLW_010_SC02_D03","External configuration: These settings are chosen by the data scientist, not discovered by the algorithm","Definition","Mentions 'external', 'chosen by scientist', or 'human decision';References 'not discovered by algorithm' or 'not learned automatically';Includes 'data scientist sets' or 'manual configuration';Shows understanding of human vs machine roles;Indicates human expertise in model setup",,,,,,,
"MLW_010_SC02_D04","Performance optimization: Adjusting settings to get the best possible results on validation data","Definition","Mentions 'performance optimization', 'best results', or 'improve accuracy';References 'validation data' or 'test performance';Includes 'adjusting settings' or 'fine-tuning';Shows understanding of goal-oriented tuning;Indicates evidence-based parameter selection",,,,,,,
"MLW_010_SC03","Documentation and reproducibility are essential for transparency and validation in research","SubConcept","Can explain that documentation involves recording every step of the process so others can understand and repeat the work;Understands that reproducibility means other researchers should be able to get the same results using the same methods and data;Recognizes that transparency involves being open about what you did, what worked, and what didn't work;Can describe how research validation allows the scientific community to check, verify, and build upon your work;Shows understanding that proper documentation and reproducibility are fundamental to scientific integrity",,,,,,,
"MLW_010_SC03_D01","Documentation: Recording every step of the process so others can understand and repeat your work","Definition","Mentions 'documentation', 'record steps', or 'write down process';References 'others can understand' or 'explain methods';Includes 'repeat work' or 'follow same steps';Shows understanding of knowledge sharing;Indicates importance of detailed records",,,,,,,
"MLW_010_SC03_D02","Reproducibility: Other researchers should be able to get the same results using your methods and data","Definition","Mentions 'reproducibility', 'same results', or 'repeat findings';References 'other researchers' or 'independent verification';Includes 'using same methods' or 'following procedure';Shows understanding of scientific validation;Indicates importance of verifiable research",,,,,,,
"MLW_010_SC03_D03","Transparency: Being open about what you did, what worked, and what didn't work","Definition","Mentions 'transparency', 'open about methods', or 'honest reporting';References 'what worked and didn't work' or 'complete picture';Includes 'share failures' or 'honest assessment';Shows understanding of research integrity;Indicates comprehensive disclosure",,,,,,,
"MLW_010_SC03_D04","Research validation: Allowing the scientific community to check, verify, and build upon your work","Definition","Mentions 'validation', 'scientific community', or 'peer review';References 'check work', 'verify results', or 'build upon';Includes 'community standards' or 'scientific method';Shows understanding of collaborative science;Indicates contribution to knowledge advancement",,,,,,,