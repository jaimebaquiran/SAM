:START_ID,:END_ID,:TYPE,description:string
mlcc_lr_v1,MLCCLR_001,CONTAINS,"ML - Linear Regression contains Supervised Learning and Linear Regression Fundamentals"
mlcc_lr_v1,MLCCLR_002,CONTAINS,"ML - Linear Regression contains Linear Regression Equation Components"
mlcc_lr_v1,MLCCLR_003,CONTAINS,"ML - Linear Regression contains Multiple Feature Linear Models"
mlcc_lr_v1,MLCCLR_004,CONTAINS,"ML - Linear Regression contains Making Predictions with Trained Models"
mlcc_lr_v1,MLCCLR_005,CONTAINS,"ML - Linear Regression contains Interpreting Model Parameters"
mlcc_lr_v1,MLCCLR_006,CONTAINS,"ML - Linear Regression contains Residuals and Prediction Errors"
mlcc_lr_v1,MLCCLR_007,CONTAINS,"ML - Linear Regression contains Loss Function Concept and Purpose"
mlcc_lr_v1,MLCCLR_008,CONTAINS,"ML - Linear Regression contains Loss Calculation Methods"
mlcc_lr_v1,MLCCLR_009,CONTAINS,"ML - Linear Regression contains Comparing and Choosing Loss Functions"
mlcc_lr_v1,MLCCLR_010,CONTAINS,"ML - Linear Regression contains Training Objective and Empirical Risk Minimization"
mlcc_lr_v1,MLCCLR_011,CONTAINS,"ML - Linear Regression contains Gradient Descent Algorithm Fundamentals"
mlcc_lr_v1,MLCCLR_012,CONTAINS,"ML - Linear Regression contains Gradient Calculation and Parameter Updates"
mlcc_lr_v1,MLCCLR_013,CONTAINS,"ML - Linear Regression contains Learning Rate Hyperparameter"
mlcc_lr_v1,MLCCLR_014,CONTAINS,"ML - Linear Regression contains Batch, Mini-Batch, and Stochastic Gradient Descent"
mlcc_lr_v1,MLCCLR_015,CONTAINS,"ML - Linear Regression contains Model Convergence and Stopping Criteria"
mlcc_lr_v1,MLCCLR_016,CONTAINS,"ML - Linear Regression contains Loss Curves and Training Diagnostics"
mlcc_lr_v1,MLCCLR_017,CONTAINS,"ML - Linear Regression contains Convex Loss Functions in Linear Regression"
mlcc_lr_v1,MLCCLR_018,CONTAINS,"ML - Linear Regression contains Feature Scaling and Normalization"
mlcc_lr_v1,MLCCLR_019,CONTAINS,"ML - Linear Regression contains Generalization and Overfitting"
mlcc_lr_v1,MLCCLR_020,CONTAINS,"ML - Linear Regression contains Regularization in Linear Regression"
MLCCLR_001,MLCCLR_002,PREREQUISITE,"Understanding supervised learning fundamentals is prerequisite for learning equation components"
MLCCLR_002,MLCCLR_003,PREREQUISITE,"Understanding basic linear equation components is prerequisite for extending to multiple features"
MLCCLR_002,MLCCLR_004,PREREQUISITE,"Understanding equation components is prerequisite for making predictions with trained models"
MLCCLR_002,MLCCLR_005,PREREQUISITE,"Understanding equation components is prerequisite for interpreting model parameters"
MLCCLR_004,MLCCLR_006,PREREQUISITE,"Understanding how to make predictions is prerequisite for calculating prediction errors"
MLCCLR_006,MLCCLR_007,PREREQUISITE,"Understanding residuals and prediction errors is prerequisite for understanding loss functions"
MLCCLR_007,MLCCLR_008,PREREQUISITE,"Understanding loss function concept is prerequisite for learning specific loss calculation methods"
MLCCLR_008,MLCCLR_009,PREREQUISITE,"Understanding loss calculation methods is prerequisite for comparing and choosing loss functions"
MLCCLR_008,MLCCLR_010,PREREQUISITE,"Understanding loss calculation methods is prerequisite for understanding training objectives"
MLCCLR_010,MLCCLR_011,PREREQUISITE,"Understanding training objectives is prerequisite for learning gradient descent algorithm"
MLCCLR_011,MLCCLR_012,PREREQUISITE,"Understanding gradient descent fundamentals is prerequisite for learning gradient calculation details"
MLCCLR_012,MLCCLR_013,PREREQUISITE,"Understanding gradient calculation and parameter updates is prerequisite for learning about learning rate"
MLCCLR_011,MLCCLR_014,PREREQUISITE,"Understanding gradient descent fundamentals is prerequisite for learning batch variants"
MLCCLR_013,MLCCLR_014,PREREQUISITE,"Understanding learning rate is prerequisite for understanding batch gradient descent variants"
MLCCLR_011,MLCCLR_015,PREREQUISITE,"Understanding gradient descent fundamentals is prerequisite for understanding model convergence"
MLCCLR_015,MLCCLR_016,PREREQUISITE,"Understanding convergence criteria is prerequisite for interpreting loss curves"
MLCCLR_008,MLCCLR_017,PREREQUISITE,"Understanding loss calculation methods is prerequisite for understanding convex loss functions"
MLCCLR_011,MLCCLR_018,PREREQUISITE,"Understanding gradient descent fundamentals is prerequisite for understanding feature scaling importance"
MLCCLR_010,MLCCLR_019,PREREQUISITE,"Understanding training objectives is prerequisite for understanding generalization and overfitting"
MLCCLR_019,MLCCLR_020,PREREQUISITE,"Understanding overfitting is prerequisite for learning regularization techniques"
MLCCLR_001,MLCCLR_003,ALLOWS_UNDERSTANDING_OF,"Supervised learning fundamentals allow understanding of multiple feature models"
MLCCLR_001,MLCCLR_007,ALLOWS_UNDERSTANDING_OF,"Understanding supervised learning fundamentals allows understanding of loss function purpose"
MLCCLR_003,MLCCLR_005,ALLOWS_UNDERSTANDING_OF,"Understanding multiple features allows deeper understanding of parameter interpretation"
MLCCLR_005,MLCCLR_018,ALLOWS_UNDERSTANDING_OF,"Understanding parameter interpretation allows understanding of why feature scaling matters"
MLCCLR_007,MLCCLR_010,ALLOWS_UNDERSTANDING_OF,"Understanding loss function concept allows understanding of training objectives"
MLCCLR_009,MLCCLR_019,ALLOWS_UNDERSTANDING_OF,"Understanding loss function choices allows understanding of generalization challenges"
MLCCLR_013,MLCCLR_016,ALLOWS_UNDERSTANDING_OF,"Understanding learning rate allows understanding of loss curve patterns"
MLCCLR_016,MLCCLR_015,ALLOWS_UNDERSTANDING_OF,"Understanding loss curves allows understanding of when convergence occurs"
MLCCLR_017,MLCCLR_015,ALLOWS_UNDERSTANDING_OF,"Understanding convex loss functions allows understanding of convergence guarantees"
MLCCLR_001,MLCCLR_002,DIFFICULTY_PROGRESSION,"Foundational supervised learning progresses to intermediate equation components"
MLCCLR_002,MLCCLR_003,DIFFICULTY_PROGRESSION,"Basic single-feature equations progress to intermediate multiple-feature models"
MLCCLR_002,MLCCLR_004,DIFFICULTY_PROGRESSION,"Understanding equation components progresses to applying them for predictions"
MLCCLR_004,MLCCLR_005,DIFFICULTY_PROGRESSION,"Making predictions progresses to interpreting what parameters mean"
MLCCLR_006,MLCCLR_007,DIFFICULTY_PROGRESSION,"Understanding residuals progresses to formalizing them as loss functions"
MLCCLR_007,MLCCLR_008,DIFFICULTY_PROGRESSION,"Loss function concepts progress to specific calculation methods"
MLCCLR_008,MLCCLR_009,DIFFICULTY_PROGRESSION,"Learning calculation methods progresses to comparing and choosing between them"
MLCCLR_010,MLCCLR_011,DIFFICULTY_PROGRESSION,"Understanding training objectives progresses to learning optimization algorithms"
MLCCLR_011,MLCCLR_012,DIFFICULTY_PROGRESSION,"Gradient descent fundamentals progress to detailed gradient calculations"
MLCCLR_012,MLCCLR_013,DIFFICULTY_PROGRESSION,"Understanding gradient updates progresses to learning rate hyperparameter tuning"
MLCCLR_011,MLCCLR_014,DIFFICULTY_PROGRESSION,"Basic gradient descent progresses to advanced batch variants"
MLCCLR_014,MLCCLR_015,DIFFICULTY_PROGRESSION,"Understanding gradient descent variants progresses to convergence analysis"
MLCCLR_015,MLCCLR_016,DIFFICULTY_PROGRESSION,"Understanding convergence progresses to diagnostic techniques with loss curves"
MLCCLR_011,MLCCLR_017,DIFFICULTY_PROGRESSION,"Gradient descent fundamentals progress to advanced convexity theory"
MLCCLR_012,MLCCLR_018,DIFFICULTY_PROGRESSION,"Understanding parameter updates progresses to feature scaling optimization"
MLCCLR_010,MLCCLR_019,DIFFICULTY_PROGRESSION,"Training objectives progress to advanced generalization concepts"
MLCCLR_019,MLCCLR_020,DIFFICULTY_PROGRESSION,"Understanding overfitting progresses to regularization solutions"
MLCCLR_002,MLCCLR_005,CROSS_REFERENCES,"Equation components and parameter interpretation mutually reinforce understanding"
MLCCLR_005,MLCCLR_002,CROSS_REFERENCES,"Parameter interpretation and equation components mutually reinforce understanding"
MLCCLR_006,MLCCLR_007,CROSS_REFERENCES,"Residuals and loss functions mutually illuminate error measurement"
MLCCLR_007,MLCCLR_006,CROSS_REFERENCES,"Loss functions and residuals mutually illuminate error measurement"
MLCCLR_008,MLCCLR_009,CROSS_REFERENCES,"Loss calculation methods and comparison criteria mutually reinforce selection"
MLCCLR_009,MLCCLR_008,CROSS_REFERENCES,"Loss function comparison and calculation methods mutually reinforce selection"
MLCCLR_013,MLCCLR_016,CROSS_REFERENCES,"Learning rate and loss curves mutually illuminate training behavior"
MLCCLR_016,MLCCLR_013,CROSS_REFERENCES,"Loss curves and learning rate mutually illuminate training behavior"
MLCCLR_015,MLCCLR_016,CROSS_REFERENCES,"Convergence criteria and loss curves mutually reinforce training diagnostics"
MLCCLR_016,MLCCLR_015,CROSS_REFERENCES,"Loss curves and convergence criteria mutually reinforce training diagnostics"
MLCCLR_017,MLCCLR_015,CROSS_REFERENCES,"Convex loss functions and convergence guarantees mutually reinforce optimization theory"
MLCCLR_015,MLCCLR_017,CROSS_REFERENCES,"Convergence and convex loss functions mutually reinforce optimization theory"
MLCCLR_019,MLCCLR_020,CROSS_REFERENCES,"Overfitting and regularization mutually illuminate generalization strategies"
MLCCLR_020,MLCCLR_019,CROSS_REFERENCES,"Regularization and overfitting mutually illuminate generalization strategies"
MLCCLR_002,MLCCLR_003,CONCEPTUAL_CLUSTER,"Equation components and multiple features belong to model structure cluster"
MLCCLR_003,MLCCLR_002,CONCEPTUAL_CLUSTER,"Multiple features and equation components belong to model structure cluster"
MLCCLR_002,MLCCLR_005,CONCEPTUAL_CLUSTER,"Equation components and parameter interpretation belong to model structure cluster"
MLCCLR_005,MLCCLR_002,CONCEPTUAL_CLUSTER,"Parameter interpretation and equation components belong to model structure cluster"
MLCCLR_003,MLCCLR_005,CONCEPTUAL_CLUSTER,"Multiple features and parameter interpretation belong to model structure cluster"
MLCCLR_005,MLCCLR_003,CONCEPTUAL_CLUSTER,"Parameter interpretation and multiple features belong to model structure cluster"
MLCCLR_006,MLCCLR_007,CONCEPTUAL_CLUSTER,"Residuals and loss functions belong to error measurement cluster"
MLCCLR_007,MLCCLR_006,CONCEPTUAL_CLUSTER,"Loss functions and residuals belong to error measurement cluster"
MLCCLR_006,MLCCLR_008,CONCEPTUAL_CLUSTER,"Residuals and loss calculation methods belong to error measurement cluster"
MLCCLR_008,MLCCLR_006,CONCEPTUAL_CLUSTER,"Loss calculation methods and residuals belong to error measurement cluster"
MLCCLR_007,MLCCLR_008,CONCEPTUAL_CLUSTER,"Loss function concept and calculation methods belong to error measurement cluster"
MLCCLR_008,MLCCLR_007,CONCEPTUAL_CLUSTER,"Loss calculation methods and loss function concept belong to error measurement cluster"
MLCCLR_007,MLCCLR_009,CONCEPTUAL_CLUSTER,"Loss function concept and comparison belong to error measurement cluster"
MLCCLR_009,MLCCLR_007,CONCEPTUAL_CLUSTER,"Loss function comparison and concept belong to error measurement cluster"
MLCCLR_008,MLCCLR_009,CONCEPTUAL_CLUSTER,"Loss calculation methods and comparison belong to error measurement cluster"
MLCCLR_009,MLCCLR_008,CONCEPTUAL_CLUSTER,"Loss function comparison and calculation methods belong to error measurement cluster"
MLCCLR_011,MLCCLR_012,CONCEPTUAL_CLUSTER,"Gradient descent fundamentals and gradient calculation belong to optimization cluster"
MLCCLR_012,MLCCLR_011,CONCEPTUAL_CLUSTER,"Gradient calculation and gradient descent fundamentals belong to optimization cluster"
MLCCLR_011,MLCCLR_013,CONCEPTUAL_CLUSTER,"Gradient descent fundamentals and learning rate belong to optimization cluster"
MLCCLR_013,MLCCLR_011,CONCEPTUAL_CLUSTER,"Learning rate and gradient descent fundamentals belong to optimization cluster"
MLCCLR_011,MLCCLR_014,CONCEPTUAL_CLUSTER,"Gradient descent fundamentals and batch variants belong to optimization cluster"
MLCCLR_014,MLCCLR_011,CONCEPTUAL_CLUSTER,"Batch variants and gradient descent fundamentals belong to optimization cluster"
MLCCLR_012,MLCCLR_013,CONCEPTUAL_CLUSTER,"Gradient calculation and learning rate belong to optimization cluster"
MLCCLR_013,MLCCLR_012,CONCEPTUAL_CLUSTER,"Learning rate and gradient calculation belong to optimization cluster"
MLCCLR_012,MLCCLR_014,CONCEPTUAL_CLUSTER,"Gradient calculation and batch variants belong to optimization cluster"
MLCCLR_014,MLCCLR_012,CONCEPTUAL_CLUSTER,"Batch variants and gradient calculation belong to optimization cluster"
MLCCLR_013,MLCCLR_014,CONCEPTUAL_CLUSTER,"Learning rate and batch variants belong to optimization cluster"
MLCCLR_014,MLCCLR_013,CONCEPTUAL_CLUSTER,"Batch variants and learning rate belong to optimization cluster"
MLCCLR_015,MLCCLR_016,CONCEPTUAL_CLUSTER,"Convergence and loss curves belong to training diagnostics cluster"
MLCCLR_016,MLCCLR_015,CONCEPTUAL_CLUSTER,"Loss curves and convergence belong to training diagnostics cluster"
MLCCLR_015,MLCCLR_017,CONCEPTUAL_CLUSTER,"Convergence and convex loss functions belong to training diagnostics cluster"
MLCCLR_017,MLCCLR_015,CONCEPTUAL_CLUSTER,"Convex loss functions and convergence belong to training diagnostics cluster"
MLCCLR_016,MLCCLR_017,CONCEPTUAL_CLUSTER,"Loss curves and convex loss functions belong to training diagnostics cluster"
MLCCLR_017,MLCCLR_016,CONCEPTUAL_CLUSTER,"Convex loss functions and loss curves belong to training diagnostics cluster"
MLCCLR_019,MLCCLR_020,CONCEPTUAL_CLUSTER,"Generalization and regularization belong to model validation cluster"
MLCCLR_020,MLCCLR_019,CONCEPTUAL_CLUSTER,"Regularization and generalization belong to model validation cluster"
MLCCLR_004,MLCCLR_001,SYNTHESIZES,"Making predictions synthesizes supervised learning fundamentals"
MLCCLR_004,MLCCLR_002,SYNTHESIZES,"Making predictions synthesizes equation components"
MLCCLR_005,MLCCLR_002,SYNTHESIZES,"Interpreting parameters synthesizes equation components"
MLCCLR_005,MLCCLR_003,SYNTHESIZES,"Interpreting parameters synthesizes multiple feature models"
MLCCLR_010,MLCCLR_007,SYNTHESIZES,"Training objectives synthesize loss function concepts"
MLCCLR_010,MLCCLR_008,SYNTHESIZES,"Training objectives synthesize loss calculation methods"
MLCCLR_014,MLCCLR_011,SYNTHESIZES,"Batch gradient descent variants synthesize gradient descent fundamentals"
MLCCLR_014,MLCCLR_012,SYNTHESIZES,"Batch gradient descent variants synthesize gradient calculations"
MLCCLR_016,MLCCLR_013,SYNTHESIZES,"Loss curves synthesize learning rate effects"
MLCCLR_016,MLCCLR_015,SYNTHESIZES,"Loss curves synthesize convergence criteria"
MLCCLR_018,MLCCLR_011,SYNTHESIZES,"Feature scaling synthesizes gradient descent optimization"
MLCCLR_018,MLCCLR_012,SYNTHESIZES,"Feature scaling synthesizes gradient calculation efficiency"
MLCCLR_020,MLCCLR_008,SYNTHESIZES,"Regularization synthesizes loss calculation methods"
MLCCLR_020,MLCCLR_010,SYNTHESIZES,"Regularization synthesizes training objectives"
MLCCLR_020,MLCCLR_019,SYNTHESIZES,"Regularization synthesizes overfitting prevention"
MLCCLR_002,MLCCLR_001,SPECIALIZES,"Linear regression equation components specialize supervised learning fundamentals"
MLCCLR_003,MLCCLR_002,SPECIALIZES,"Multiple feature models specialize basic linear regression equations"
MLCCLR_004,MLCCLR_002,SPECIALIZES,"Making predictions specializes applying equation components"
MLCCLR_008,MLCCLR_007,SPECIALIZES,"Loss calculation methods specialize loss function concepts"
MLCCLR_009,MLCCLR_007,SPECIALIZES,"Comparing loss functions specializes loss function concepts"
MLCCLR_012,MLCCLR_011,SPECIALIZES,"Gradient calculation specializes gradient descent algorithm"
MLCCLR_013,MLCCLR_011,SPECIALIZES,"Learning rate hyperparameter specializes gradient descent algorithm"
MLCCLR_014,MLCCLR_011,SPECIALIZES,"Batch gradient descent variants specialize gradient descent algorithm"
MLCCLR_016,MLCCLR_015,SPECIALIZES,"Loss curves specialize convergence diagnostics"
MLCCLR_017,MLCCLR_011,SPECIALIZES,"Convex loss functions specialize gradient descent optimization theory"
MLCCLR_018,MLCCLR_011,SPECIALIZES,"Feature scaling specializes gradient descent optimization"
MLCCLR_020,MLCCLR_010,SPECIALIZES,"Regularization specializes training objectives"